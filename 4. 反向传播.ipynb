{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(23455)\n",
    "X = rng.rand(32, 2)\n",
    "Y = [[int(x0 + x1 < 1)] for (x0, x1) in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After     0 training step, loss on all data is 38.105251\n",
      "After   500 training step, loss on all data is 2.544636\n",
      "After  1000 training step, loss on all data is 2.603659\n",
      "After  1500 training step, loss on all data is 2.623431\n",
      "After  2000 training step, loss on all data is 2.629595\n",
      "After  2500 training step, loss on all data is 2.631502\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y_ = tf.matmul(a, w2)\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(y - y_))\n",
    "train = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    STEPS = 3000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * BATCH_SIZE) % 32\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train, feed_dict={x:X[start:end], y:Y[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            print(\"After %5d training step, loss on all data is %f\" % (i, sess.run(loss, feed_dict={x: X[start:end], y: Y[start:end]})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建神经网络的八股：\n",
    "\n",
    " - 准备：\n",
    "     - 定义网络中的超参数，batch_size， steps等\n",
    " - 前向传播：\n",
    "     - 定义输入，参数，输出\n",
    " - 反向传播：\n",
    "     - 定义损失函数，优化器\n",
    " - 生成会话：\n",
    "     - 训练STEP步"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
